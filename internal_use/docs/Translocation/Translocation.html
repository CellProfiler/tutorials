<h1 id="image-based-screening-using-subcellular-localization-of-foxo1a-in-osteosarcoma-cells-a-computer-exercise-using-cellprofiler-cellprofiler-analyst-software">Image-based screening using subcellular localization of FOXO1A in osteosarcoma cells: A computer exercise using CellProfiler &amp; CellProfiler Analyst software</h1>
<p>Beth Cimini, Carolina Wählby, Martin Simonsson, Megan Rokop and Mark Bray, Broad Institute</p>
<p><strong>*Background information:</strong>*</p>
<p>In this experiment, we are working with human U2OS osteosarcoma (bone cancer) cells, in which a Forkhead-protein FOXO1A has been labeled with GFP (Green Fluorescent Protein). In proliferating cells, FOXO1A is localized in the cytoplasm; it is constantly moving into the nucleus, but is transported out again by export proteins. Upon inhibition of nuclear export, FOXO1A accumulates in the nucleus. We know that 150nM of Wortmannin (the drug we are using as a positive control in this experiment) inhibits transport of the FOXO1A protein from the nucleus back out to the cytoplasm (Fig. 1). Labeling FOXO1A with GFP allows us to visualize its subcellular localization. The goal of developing image-based screens of this type is to aid in the search for unknown drugs that have the same effect as Wortmannin on FOXO1A subcellular localization (and hence may be possible treatments for osteosarcoma patients), but possess fewer side effects than the known drugs.</p>
<blockquote>
<table style="width:28%;">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<tbody>
<tr class="odd">
<td><img src="./TutorialImages/Fig1A.png" width="300" alt="Fig1A" /></td>
<td><img src="./TutorialImages/Fig1B.png" width="300" alt="Fig1B" /></td>
</tr>
</tbody>
</table>
</blockquote>
<p><em>Figure 1: Examples of FOXO1A-GFP localization. Left: Cytoplasmic localization in untreated cells. Right: Nuclear localization in Wortmannin treated cells. GFP: Green, DNA: red.</em></p>
<p><strong>Goals of this exercise:</strong></p>
<p>In this exercise, we aim to: (1) determine this lowest possible dose necessary to observe this effect, and (2) to optimize the analysis of images in which FOXO1A is cytoplasmic versus nuclear, in order to separate positive controls and negative controls as best as possible.</p>
<p><strong>Materials necessary for this exercise:</strong></p>
<p>The images you will be analyzing were taken from cells growing in a standard 96-well plate, but you will work with a subset of only 26 of these images: 8 wells were left untreated (and were therefore negative controls), 8 wells were treated with the maximum dose of the drug Wortmannin (and were therefore positive controls), and 10 wells were used to create a dose gradient with increasing concentration of the drug. In addition to these images, a text file called “Translocation_doses_and_controls.csv” is provided, containing information about where on the 96-well plate the wells were located, and how the cells were treated.</p>
<p><strong>Methods to be used in this exercise:</strong></p>
<p>In this exercise, you will use CellProfiler and CellProfiler Analyst to identify and delineate (or “segment”) each nucleus and cell body, and extract a number of measurements from each cell. You have a total of 26 images, with approximately 200 cells per image, so you want to automate the process of identifying and segmenting the cells. The first task is to set up a CellProfiler <strong>pipeline</strong> consisting of a number of individual <strong>modules</strong>; each module performs a unique image-processing step, and multiple modules can be arranged such that they are executed in sequential order. You will test your pipeline on a few images so that you can optimize the settings. Once optimization is complete, you will run the pipeline on all the images in the experiment, collect measurements from each cell and store them in a database. At this point, you will use CellProfiler Analyst to visualize your data, and use its machine learning tool to train the computer to distinguish between treated and untreated cells.</p>
<h2 id="exercise-i-using-the-cellprofiler-software-to-identify-features-and-obtain-measurements-from-cellular-images.">Exercise I: Using the CellProfiler software to identify features and obtain measurements from cellular images.</h2>
<ol type="1">
<li><strong>Starting CellProfiler and configuring the input data for analysis</strong></li>
</ol>
<ul>
<li>Start CellProfiler by double-clicking the desktop icon <img src="./TutorialImages/Inline01.png" width="25" alt="Inline01" /></li>
<li>In the CellProfiler interface, you will see the File list panel, a blank panel indicated by the text “Drop files and folders here”. The File list panel is the main interface of the <em>Images</em> module, which compiles a list of files and/or folders that you want to analyze; this module is highlighted in the Input modules panel which is located at the upper-left of CellProfiler.</li>
<li>From File Explorer (Windows) or Finder (Mac), drag and drop the “TranslocationData” folder into this panel. The names of your files in the TranslocationData folder should now appear in the File list panel. Double-click on “BBBC013_A01_s1_w1.tif” and “BBBC013_A12_s1_w1.tif” to see what examples of negative and positive GFP controls look like, respectively.</li>
<li>Scroll to the bottom of the File list and note that in addition to the image files, there is a file called “Translocation_doses_and_controls.csv”. We only want image files to be analyzed in CellProfiler so this file needs to be removed from consideration.</li>
<li>Under the Module settings panel (below the File list), you will see a control for specifying which files should be used from the above list. Click on the “Update file list” button to filter out the non-image files using the default settings. You will see that the CSV file is then grayed-out in the list, indicating that it will not be used.</li>
<li>Click on the <em>Metadata</em> module, which is the second module in the Input module panel; this module allows you to provide information about the drug dosages and location on the plate.</li>
<li>The first extraction set up for you in the <em>Metadata</em> module extracts information about the plate, well, site, and channel of each image by parsing the file name.</li>
<li>Click the magnifying glass icon <img src="./TutorialImages/Inline02.png" width="25" alt="Inline02" /> to the right of the text box labeled “Regular expression”.
<ul>
<li>A new dialog box will appear to assist in comparing the entered regular expression against an example image filename.</li>
<li>You will see the color of the “Plate”, “Well”, “Site” and “ChannelNumber” text match the color of the corresponding portion in the Test text below.</li>
<li>Once finished, click the “Submit” button to use this expression in the <em>Metadata</em> module.</li>
</ul></li>
<li>The second metadata extraction step requires you to tell CellProfiler the location of a CSV file. It is looking for it in CellProfiler's Default Input Folder, which we must therefore configure.
<ul>
<li>This is the file describing the image names, locations in the 96-well plate, and doses.</li>
<li>Click the file selection box next to "Metadata file name" line and navigate to the location of the TranslocationData folder on your computer, then select the <strong>Translocation_doses_and_controls.csv</strong> file within.</li>
</ul></li>
<li>Return to the ‘Metadata’ module and press ‘Update’. You should now see a number of columns in the Metadata window.
<ul>
<li>If you examine the metadata matching, you can see that “Well” is selected from both drop-downs under “CSV Metadata” and “Image Metadata”. This indicates that the information stored in the CSVs "Well" column should be matched to the well metadata values obtained from the filename in the first extraction step.</li>
</ul></li>
<li>Next to the setting labeled “Metadata data type”, make sure “Choose for each” is selected from the drop-down. For the “Dose” metadata, select “Float” as the data type. Leave the remaining metadata at the default “Text” values.</li>
<li>Click on the <em>NamesAndTypes</em> module, which is the third module in the Input module panel; this module allows you to assign a meaningful name to each image by which other modules will refer to it.</li>
<li>Note how the images are assigned to channels: images containing "w1" in their file name are assigned to the name "rawGFP", while those with "w2" are assigned "rawDNA".</li>
<li>Click the “Update” button below the divider to display a table that shows each channel pair matched up for the 26 wells in the assay.</li>
</ul>
<ol start="2" type="1">
<li><strong>Identifying the nuclei as the “primary objects” that you will analyze</strong></li>
</ol>
<p>Now that the module inputs and outputs are set up, in your module, the remaining settings need to be adjusted to best detect the nuclei. The most effective approach for this task is to use CellProfiler’s “Test mode,” which will allow you to see the results of your chosen settings, and adjust them as needed.</p>
<ul>
<li>Click the “Start Test Mode” button to the bottom-left of the CellProfiler interface. You will see <img src="./TutorialImages/Inline04.png" width="15" alt="Inline04" /> icons appear next to the modules in the pipeline, as well as new buttons appear below the modules.</li>
<li>Click on the “Step” button below the pipeline panel, in order to progress through each module in the pipeline, one by one. Upon stepping through the <em>IdentifyPrimaryObjects</em> module, a module display window will appear similar to that shown in Figure 2 below.</li>
</ul>
<figure>
<img src="./TutorialImages/Fig2.png" class="align-center" width="500" alt="Figure 2: Example module display window for IdentifyPrimaryObjects ." /><figcaption aria-hidden="true"><em>Figure 2: Example module display window for IdentifyPrimaryObjects .</em></figcaption>
</figure>
<p>For the <em>IdentifyPrimaryObjects</em> module, the goal is to have the outlines match the actual nuclei boundaries as well as possible, as well as separating touching objects accurately. Said another way, you do not want the program to split a single object (in this case, a single nucleus) into multiple objects, and you do not want the program to merge multiple objects into a single object.</p>
<p>The results of <em>IdentifyPrimaryObjects</em> are displayed in four panels in the display window, as shown in Fig. 2:</p>
<ul>
<li>Upper left: The raw image, titled as “Input image, cycle #” plus the image number</li>
<li>Upper right: A colored image of the identified and labeled objects, titled with the object name (in this case, “Nuclei”). Note that the colors themselves are arbitrary, intended to distinguish each identified object from its neighbors.</li>
<li>Lower left: An image of the object outlines superimposed on the raw image, titled with the object name. Green outlines around an object indicate that the object has passed the selection criteria in the module. Yellow outlines indicate that the object touches the image edge, and has therefore been excluded. Pink outlines indicate objects that do not pass a size criterion, and have therefore been excluded.</li>
<li>Lower right: A table of module setting values and statistics</li>
</ul>
<p>There are some image tools on the top toolbar that may be helpful to see the individual objects:</p>
<p><img src="./TutorialImages/Inline05.png" alt="Inline05" /></p>
<p>The 1st icon from the left lets you reset the view back to the original view.</p>
<p>The 2nd and 3rd icons let you step backwards and forwards through any changes you made to the view.</p>
<p>The 4th icon lets you change the view by moving in any direction in the display, by clicking and dragging.</p>
<p>The 5th icon lets you change the view by zooming, by dragging and drawing a box to zoom in on.</p>
<ul>
<li>Zoom in the image in order to see the quality of the nuclei identification. The result may look like Figure 3.</li>
</ul>
<figure>
<img src="./TutorialImages/Fig3.png" class="align-center" width="500" alt="Figure 3: A zoomed-in view of the display window for IdentifyPrimaryObjects" /><figcaption aria-hidden="true"><em>Figure 3: A zoomed-in view of the display window for IdentifyPrimaryObjects</em></figcaption>
</figure>
<ol start="3" type="1">
<li><strong>Improve identification of primary objects</strong></li>
</ol>
<p>In this instance, in Figure 3, you can see that the outlines capture too much of the background around the nuclei. This means that the default automated thresholding method calculated a threshold value that is too low. We can correct this with a change in the thresholding method used. Since we are in Test Mode, we can easily adjust the module settings and quickly preview the results.</p>
<ul>
<li>Objects outlined in pink are outside the "Typical diameter" pixel range specified in the pipeline. Use the "Tools-&gt;Measure length" tool to determine if the size range specified is correct given the size of your objects.</li>
<li>We can figure out why the thresholding method is overly lenient by looking closer at the original image.
<ul>
<li>Right-click on the “Input image, cycle #” panel in the IdentifyPrimaryObjects display window and select “Image Contrast” and then “Log normalized.” This log-transforms the image intensity such that the contrast between low pixel intensities is enhanced and that between high pixel intensities is reduced.</li>
<li>Do the same for the “Nuclei outlines” image in the display window.</li>
</ul></li>
</ul>
<p>Most thresholding methods assume that there are two intensity distributions present in the image, one of which is categorized as foreground and the other as background; the objective is then to find a single value that separates them. There are different methods to calculate this intensity threshold automatically. In order to learn more about these methods, click on the question mark icon to the right of the "Thresholding method" to open the CellProfiler help.</p>
<p>You'll note that the Translocation_start pipeline uses the Robust background method initially. This method can be helpful if the majority of the image is background. In this example, however, the nuclei cover a large percentage of the image and Robust Background method is not the optimal choice. We recommend selecting the Otsu method instead.</p>
<p>Now, examine your original image again. In this image, there appear to be instead three classes of staining intensity: the nuclei (high intensity), the actual background (low intensity), and the non-specific staining outside the nuclei but within the cell body (medium intensity). An alternative thresholding method would need to take these intensity gradations into account in order to improve the nuclei detection.</p>
<ul>
<li>Click the <em>IdentifyPrimaryObjects</em> setting labeled “Two-class or three-class thresholding?” and select “Three classes.”</li>
<li>Change the setting “Assign pixels…” that subsequently appears underneath from “Foreground” to “Background.”</li>
<li>Click the “Step” button again to see the result from your new settings.</li>
<li>Adjust the "Threshold correction factor" to 1.</li>
</ul>
<p>This thresholding approach takes the medium-intensity pixels and assigns them as background pixels, leaving only the highest intensity pixels as background. The identified outlines should now better match the actual nuclei boundaries.</p>
<ol start="4" type="1">
<li><strong>Identifying the cell body as a “secondary object” that you will analyze</strong></li>
</ol>
<p>Now that you have confirmed, by eye, that the settings we provided you in this exercise do allow for identification and segmentation of the nuclei, you can now find the entire cell using <em>IdentifySecondaryObjects</em> module.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>IdentifySecondaryObjects</em>, which is located under the module category <em>“Object Processing”.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>For the “Select the input image” module setting, select “rawGFP” from the drop-down list.</li>
<li>For the “Select input objects” setting, select “Nuclei” from the drop-down list.</li>
<li>For the “Name the objects to be identified” setting, enter “Cells” as a descriptive name for the secondary objects.</li>
<li>Click the drop-down box next to “Threshold strategy” and select “Global.” Then, click the drop-down next to “Thresholding method to select “Otsu”.</li>
<li>Click the setting labeled “Two-class or three-class thresholding?” and change it from “Two classes” to “Three classes.” Change the setting “Assign pixels…” that subsequently appears underneath to “Foreground”</li>
<li>Click on the “Step” button to execute the module and see the results of secondary object identification using the module settings (Fig. 4).
<ul>
<li>By default, secondary objects are identified with the Propagation method, which defines cell boundaries by “growing” outwards from the primary objects, i.e. the nuclei, and taking into account both the distance from the nearest primary object, and the local intensity in the GFP image.</li>
<li>Note that the pink and green outlines do not have the same meaning as in the <em>IdentifyPrimaryObjects</em> display window. In <em>IdentifySecondaryObjects</em>, the pink outlines indicate the secondary object boundaries and the green outlines indicate the primary object boundaries.</li>
</ul></li>
</ul>
<figure>
<img src="./TutorialImages/Fig4.png" class="align-center" width="500" alt="Figure 4: Example module display window for IdentifySecondaryObjects." /><figcaption aria-hidden="true"><em>Figure 4: Example module display window for IdentifySecondaryObjects</em>.</figcaption>
</figure>
<p>In contrast to the DNA stain in <em>IdentifyPrimaryObjects</em>, the middle intensity levels associated with the dim cells are assigned as foreground pixels, so that the secondary objects captures both the dim and bright cells.</p>
<p>However, for this assay, we may prefer to use a segmentation method that reflects the actual cell boundaries and is not dependent on an intensity that varies from treatment to treatment. We will take a look at the Distance-N method which expands outward from the nucleus a fixed number of pixels without regard to the underlying fluorescence.</p>
<ul>
<li>Change the “Select method…” setting from “Propagation” to “Distance-N.”</li>
<li>Change the setting “Number of pixels by which to expand…” that appears underneath to 10 pixels.</li>
<li>Click the “Step” button to see the result from your new settings.</li>
</ul>
<ol start="5" type="1">
<li><strong>Identifying the cytoplasm as a “tertiary object”</strong></li>
</ol>
<p>Once we have identified the nucleus and the cell body, these two objects can be used to define the cell cytoplasm as the region outside the nucleus, but within the cell boundary. We will use the <em>IdentifyTertiaryObjects</em> module which will take the smaller identified objects and “subtract” (or remove) them from the larger identified objects, effectively identifying the cytoplasm.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>IdentifyTertiaryObjects</em> located under the module category <em>“Object Processing”.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>In this module, for the “Select the larger identified objects” module setting, select “Cells” from the drop-down list.</li>
<li>For the “Select the smaller identified objects” setting, select “Nuclei” from the drop-down list.</li>
<li>For the “Name the tertiary objects to be identified” setting, enter “Cytoplasm” as a descriptive name for the tertiary objects.</li>
<li>Enable the ‘Shrink smaller object prior to subtraction?’ option; this will ensure that all of your Cytoplasm objects have an area of at least 1 pixel.</li>
<li>Click the “Step” button to execute the module, and preview the results of tertiary object identification (Fig. 5).</li>
</ul>
<figure>
<img src="./TutorialImages/Fig5.png" class="align-center" width="500" alt="Figure 5: Example module display window for IdentifyTertiaryObjects." /><figcaption aria-hidden="true"><em>Figure 5: Example module display window for IdentifyTertiaryObjects</em>.</figcaption>
</figure>
<ol start="6" type="1">
<li><strong>Measuring the cells’ characteristics (i.e. the “object features”)</strong></li>
</ol>
<p>Now that the objects have been identified using settings that have been optimized for the phenotypes of interest, the next step is to make measurements of the various cellular features. Later, we will be using CellProfiler Analyst to classify the cells into phenotypes, based on whether they contain cytoplasmic or nuclear FOXO1A-GFP using the measurements collected here. The important point is to collect measurements that would be useful for distinguishing one phenotype from the other.</p>
<p>CellProfiler has the ability to measure many cellular characteristics, and what we could do in this exercise, is ask it to measure all of them, and then let the classification tool decide which features are most useful. In this exercise, however, we will use three of the possible measurements.</p>
<p><strong>Measurement of pixel intensity of GFP in nuclei and cytoplasm:</strong> One example of a particularly useful measurement is the pixel intensities of the various objects (i.e. nuclei and cytoplasm) as measured from the images showing the subcellular location of the FOXO1A-GFP fluorescence.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>MeasureObjectIntensity</em> located under the module category <em>“Measurement”.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>In this module, select “rawGFP” from the drop-down list, which is next to the “Select an image to measure” setting.</li>
<li>Choose “Nuclei” from the drop-down list next to the “Select objects to measure” setting. Press the “Add another object button” and select “Cytoplasm” (from the drop-down list of the new “Select objects to measure” setting that appears when you do this).</li>
</ul>
<p><strong>Measurement of the correlation of GFP in nuclei to DNA in nuclei:</strong> Another potentially useful measure is the correlation within the objects of the pixel intensities in the GFP and DNA channels. If the FOXO1A-GFP protein is not translocated, the intensity correlation within the nucleus between the two images would be expected to be negative, whereas upon translocation, the correlation would be positive.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>MeasureColocalization</em> located under the module category <em>“Measurement”.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>In this module, select “rawGFP” and “rawDNA” from the drop-down lists next to the two “Select an image to measure” settings.</li>
<li>For the “Select where to measure correlation” setting, select “Within objects” and then select “Nuclei” from the “Select an object to measure” setting.</li>
</ul>
<p><strong>Measurement of the ratio of GFP in cytoplasm to GFP in nuclei:</strong> Since we are interested in the transportation of GFP from the cytoplasm to the nucleus, it would be useful to measure the ratio of cytoplasmic stain to nuclear stain. In this case, we will use the <em>CalculateMath</em> module because it performs arithmetic operations between various object measurements.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>CalculateMath</em> located under the <em>“Data Tools”</em> module category<em>.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>For the “Name the output measurement,” enter the “IntensityRatio” as a descriptive name.</li>
<li>Since we calculating a ratio of two measures, select “Divide” from the drop-down for the “Operation” setting.</li>
<li>For the numerator measurement:
<ul>
<li>Select “Object” for the “Select the numerator type,” and select “Nuclei” from the drop-down for the “Select the numerator objects.”</li>
<li>Select “Intensity” from the drop-down for the “Select the numerator measurement” category. A “Measurement” drop-down box will subsequently appear underneath.</li>
<li>Select “MeanIntensity” from the “Measurement” drop-down list. Then select “rawGFP” from the “Image” drop-down that appears.</li>
</ul></li>
<li>For the denominator measurement:
<ul>
<li>Select “Object” for the “Select the numerator type,” and select “Cytoplasm” from the drop-down for the “Select the numerator objects.”</li>
<li>Select “Intensity” from the drop-down for the “Select the numerator measurement” category. A “Measurement” drop-down box will subsequently appear underneath.</li>
<li>Select “MeanIntensity” from the “Measurement” drop-down list. Then select “rawGFP” from the “Image” drop-down that appears.</li>
</ul></li>
</ul>
<ol start="7" type="1">
<li><strong>Creating an image with your cell and nuclear outlines on it (optional)</strong></li>
</ol>
<p>It’s often nice to create an image showing the segmentation of your objects so that you can refer back to it later; in addition to the ability to quickly scan all the output images to make sure your segmentation was successful, you can re-check them later in case you have questions about an unusual result.</p>
<p><strong>Creation of a color image to display the segmentation:</strong></p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>GrayToColor</em> located under the <em>“Image Processing”</em> module category<em>.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>For the “Select a color scheme”, leave the setting at “RGB”.</li>
<li>For the channels
<ul>
<li>“Set the image to be colored red” set to “Leave this black”.</li>
<li>“Set the image to be colored green” set to “rawGFP”.</li>
<li>“Set the image to be colored blue” set to “rawDNA”.</li>
</ul></li>
<li>“Name the output image” can be set to “GFPandDNA” .</li>
<li>“Relative weight”s for each of the channels can be left at 1.</li>
</ul>
<p><strong>Overlaying the outlines onto the color image:</strong> This module will overlay the outlines of your identified objects onto the color image. You may choose whatever color you like to show the outlines, but you may find it easiest to use something that contrasts with your color image. You may also overlay outlines on a grayscale image; if you have many types of objects and/or more than 3 channels it is often easier to overlay the objects for each channel onto that channel’s grayscale image and simply view them one at a time.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>OverlayOutlines</em> located under the <em>“Image Processing”</em> module category<em>.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>“Display outlines on a blank image” should be set to “No”.</li>
<li>The “Select image on which to display outlines” should be set to the “GFPandDNA” image we created in the last step.</li>
<li>“Name the output image” can be set to “CellAndNucleiOverlay” or some other descriptive name.</li>
<li>The “Outline display mode” dropdown menu should be left at “Color”.</li>
<li>“How to outline” can be left at the default (Inner).</li>
<li>For “Select objects to display” select “Nuclei” from the dropdown menu.</li>
<li>“Select outline color” can be left as red or set to some other contrasting color.</li>
<li>Click the “Add another outline” button, then repeat the previous 3 steps for “Cells”; you should select a different color for the outlines.</li>
</ul>
<p><strong>Saving the overlay image:</strong> The SaveImages module can be used to either save images generated in any step of the pipeline or masks of the objects created. Here we will save the images to the DefaultOutput folder, but you can specify any other location, and additionally create subfolders based on the extracted metadata if you like.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>SaveImages</em> located under the <em>“File processing”</em> module category<em>.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.</li>
<li>For “Select the type of image to save”, select “Image”.</li>
<li>For “Select the image to save”, select your “CellAndNucleiOverlay” image you just created.</li>
<li>For “Select method for constructing file names”, keep it set at “From image filename”.</li>
<li>For “Select image name for file prefix”, select the “rawGFP” image.</li>
<li>Change the “Append a suffix to the image file name?” radio buttons to “Yes”.</li>
<li>Give the “Text to append to the image name” a descriptive name; “_Overlay” is appropriate.</li>
<li>All the other settings may be left at their default values.</li>
</ul>
<ol start="8" type="1">
<li><strong>Exporting the measurements to a database</strong></li>
</ol>
<p>Since we will be using the data visualization and machine learning tools in CellProfiler Analyst, the measurements will need to be saved to a database using the <em>ExportToDatabase</em> module in order for CellProfiler Analyst to access them.</p>
<ul>
<li>Click on the <img src="./TutorialImages/Inline03.png" width="20" alt="Inline03" /> button and add the module <em>ExportToDatabase</em> located under the module category <em>“File Processing”.</em> Add it to the pipeline by clicking the “+ Add to Pipeline” button.
<ul>
<li>Note that while in Test mode, the <em>ExportToDatabase</em> module will have a yellow warning sign in the pipeline panel and yellow-highlighted text in the module settings. Holding the mouse over the yellow-highlighted text informs the user that measurements produced in Test mode are not written to the database. This is normal behavior and does not indicate an error.</li>
</ul></li>
<li>Select “Database type” as “SQLite.”</li>
<li>Check the box labeled “Create a CellProfiler Analyst properties file.” A number of new settings will subsequently appear underneath.</li>
<li>For “Which objects should be used for locations?”, select “Nuclei”.</li>
<li>For “Select the plate type”, choose “96.”</li>
<li>For “Select the plate metadata,” choose “Plate.”</li>
<li>For “Select the well metadata,” choose “Well.”</li>
<li>For “Output file location”, select “Default Output Folder”.</li>
<li>Check the box “Write image thumbnails directly to database?” From the list-box that subsequently appears, select “rawDNA” and “rawGFP”; you can make multiple selections by using Ctrl-click (Windows) or Command-click (Mac). Leave the rest of the settings at the default values.</li>
</ul>
<ol start="9" type="1">
<li><strong>Using the optimized pipeline to automatically analyze all images generated by the screening experiment</strong></li>
</ol>
<p>At this point, the settings you have entered were chosen for you because those settings specifically, when used with these images, result in an optimized pipeline for a suitable number of images. Therefore your pipeline is now ready to run on the full data set of 26 images.</p>
<ul>
<li>Exit Test Mode by clicking the “Exit Test Mode” button at the bottom-left of the CellProfiler interface.</li>
<li>Click the “View output settings” button at the bottom-left of the interface. Then, in the module settings panel, click the folder button to the right of “Default Output Folder” box, and browse to select your Desktop. This location is where your CellProfiler measurements will be saved.</li>
<li>Select the “Window” item from the menu bar and select “Hide all windows on run;” the “eyeball” icons next to the modules will switch from open (<img src="./TutorialImages/Inline06.png" width="20" alt="Inline06" />) to closed (<img src="./TutorialImages/Inline07.png" width="20" alt="Inline07" />). This display indicates that the module display windows for each module will not be shown as each is processed. The rationale behind this step is because the pipeline is optimized, we no longer need to see the results. Additionally, the analysis will be quicker this way, since CellProfiler does not have to take the time to create and draw each window.</li>
<li>Save your pipeline by selecting <em>File &gt; Save Project As…</em>, give the pipeline a name and save it to your Desktop.</li>
<li>To analyze all images, click “Analyze images” button in the lower right corner of the CellProfiler interface.
<ul>
<li>(Windows only) A Windows Security Alert box may pop up asking for network access permission for CellProfiler.exe. Check the “Private networks” box, then click “Allow access”.</li>
</ul></li>
</ul>
<p>The pipeline will run beginning with the first of 26 images. This full run may take a few minutes.</p>
<h2 id="exercise-ii-using-the-cellprofiler-analyst-software-to-visualize-the-data-from-the-experiment-and-classify-the-cells-exposed-to-each-drug-condition-by-their-phenotype-foxo1a-gfp-subcellular-localization">Exercise II: Using the CellProfiler Analyst software to visualize the data from the experiment, and classify the cells exposed to each drug condition by their phenotype (FOXO1A-GFP subcellular localization)</h2>
<p>You can now start CellProfiler Analyst (CPA) to explore the data you have extracted from the cells.</p>
<ul>
<li>Start CellProfiler Analyst by double-clicking the icon on the desktop <img src="./TutorialImages/Inline08.png" width="25" alt="Inline08" />.</li>
<li>When CPA is started, it will ask to select a <em>properties file</em>. Select the properties file named <em>DefaultDB .properties</em>, located in the Default Output Folder. The properties file was created by the <em>ExportToDatabase</em> module in your pipeline.
<ul>
<li>This file is a text file that contains the settings necessary for CPA to connect to the database that CellProfiler generated.</li>
<li>As a reminder, this database currently contains the measurement data obtained from all 26 images, and pointers to the location of those images on your hard drive.</li>
</ul></li>
</ul>
<ol type="1">
<li><strong>Visualizing the measurements in a 96-well plate layout view</strong></li>
</ol>
<p>CPA has several tools available for displaying the data for exploration. If your data came from a multi-well plate, such as the 96-well plate for this particular translocation assay, then one of the most useful data visualization tools available is the plate layout format.</p>
<ul>
<li>Click on the Plate Viewer icon in the CPA menu (<img src="./TutorialImages/Inline09.png" alt="Inline09" />, 3rd from the left). This selection brings up a 96-well formatted display of the plate from which your images originated. The colored squares represent wells for which measurement data is present; crossed-out wells indicate wells with no measurements. Notice that 26 out of the 96 wells have data associated with them. Mouse over a few of the wells to see a “tool-tip” box appear, which states the actual per-well value.</li>
<li>The initial color coding represents the image index, a bookkeeping measurement which is not relevant for the level of analysis that we are doing in this exercise. Under the <em>Measurements</em> drop-down list, choose <em>“Image_Metadata_Dose”</em> from the list, in order to visualize the drug concentrations added to each well. In particular, take note of the following:
<ul>
<li>Column 1, rows A-D, column 12, rows E-H and well E02: Negative controls, i.e., no drug added</li>
<li>Column 1, rows E-H and column 12, rows A-D: Positive controls, i.e., 150 nM Wortmannin</li>
<li>Row E, columns 2-11: Nine doses of 2-fold dilutions of Wortmannin, increasing from left to right.</li>
</ul></li>
</ul>
<figure>
<img src="./TutorialImages/Fig6.png" class="align-center" width="600" alt="Figure 6: The Plate Viewer visualization tool illustrating the drug dosages applied to the plate." /><figcaption aria-hidden="true"><em>Figure 6: The Plate Viewer visualization tool illustrating the drug dosages applied to the plate.</em></figcaption>
</figure>
<ul>
<li>Select “<em>Image_Count_Nuclei”</em> from the <em>Measurement</em> drop-down to show the nuclei count for each image.</li>
<li>Per-object measurements can also be displayed using this tool. Select “Per-object” as the Data Source, and “<em>Cytoplasm_Math_IntensityRatio”</em> as the Measurement. Since each well can display only one value, but there are multiple objects per well, the Plate Viewer displays an aggregate statistic of the per-object measurements for each well. (Note that you can change the statistic used, at this step, by selecting it from the “Aggregation method” drop-down in the “Data aggregation” panel.)</li>
<li>In this step, you will see how the image thumbnails can also be shown in the viewer. To do this, under “Well display” in the “View options” panel, select “thumbnail.” The colored well squares will be replaced with merged color thumbnails of the original images.</li>
<li>In order to see that the original images are linked to the well display, you should right-click on a well and select the image number corresponding to the image of interest, in order to display the full image. (Note that the default color for each channel can be changed by selecting the desired colors in the menu bar; any changes will be applied to subsequent images that you open.)</li>
<li>Lastly, you will view the thumbnail montages by right-clicking on a well and selecting “Show thumbnail montage” from the resulting pop-up. Click anywhere outside of the thumbnail to dismiss it from view. (Note that, if there had been multiple snapshots of multiple fields of view for each well in the plate, then the montage would be shown as a tiled display.)</li>
<li>Do not close the Plate Viewer tool, as you will be referring to it later in the exercise.</li>
</ul>
<ol start="2" type="1">
<li><strong>Using the Classifier function of CPA to distinguish the cells’ FOXO1A-GFP subcellular localization phenotypes</strong></li>
</ol>
<p>CellProfiler Analyst contains a machine-learning classification tool, which will allow you to distinguish different phenotypes automatically. In this case, we will “train” the classifier to recognize cells in which FOXO1A-GFP is located exclusively in the nucleus (“positives”) versus outside the nucleus (“negatives”) by sorting examples of each into bins.</p>
<ul>
<li>Select the <em>Classifier</em> icon in the CPA menu (<img src="./TutorialImages/Inline10.png" alt="Inline10" />, 2nd on left). The Classifier interface will appear, similar to that shown in the top of Fig. 7.</li>
<li>Click on the “Fetch!” button, which instructs CPA to display pictures of a default number (i.e. 20) of randomly selected cells from this experiment. You will see the middle “unclassified” panel start to be populated with thumbnail images of these randomly selected cells.</li>
<li>Use your mouse to “drag &amp; drop” whichever cells you consider clearly positive (i.e. FOXO1A-GFP located exclusively in the nucleus) into the “positive” bin. See the bottom-left panel of Fig. 7 for examples of positive cells.
<ul>
<li>A small dot is displayed in the center of each thumbnail image as your mouse hovers over it. The cell that falls under this dot is the cell to “drag &amp; drop” which will be used for classification.</li>
</ul></li>
</ul>
<figure>
<img src="./TutorialImages/Fig7a.png" class="align-center" width="600" />
</figure>
<table style="width:94%;">
<colgroup>
<col style="width: 47%" />
<col style="width: 47%" />
</colgroup>
<tbody>
<tr class="odd">
<td><img src="./TutorialImages/Fig7b.png" width="50" alt="Fig7b" /> <img src="./TutorialImages/Fig7c.png" width="50" alt="Fig7c" /> <img src="./TutorialImages/Fig7d.png" width="50" alt="Fig7d" /> <img src="./TutorialImages/Fig7e.png" width="50" alt="Fig7e" /></td>
<td><img src="./TutorialImages/Fig7f.png" width="50" alt="Fig7f" /> <img src="./TutorialImages/Fig7g.png" width="50" alt="Fig7g" /> <img src="./TutorialImages/Fig7h.png" width="50" alt="Fig7h" /> <img src="./TutorialImages/Fig7i.png" width="50" alt="Fig7i" /></td>
</tr>
<tr class="even">
<td><strong>Examples of positive cells</strong></td>
<td><strong>Examples of negative cells</strong></td>
</tr>
</tbody>
</table>
<p><em>Figure 7:</em> <strong>*Top:</strong>* <em>The Classifier interface showing 5 positive and 5 negative cells. Thirty unclassified cells remain and are ready for sorting.</em> <strong>*Bottom:</strong>* <em>Examples of positive cells (left) and negative cells (right).</em></p>
<ul>
<li>Now “drag &amp; drop” whichever cells you consider clearly negative (i.e. FOXO1A-GFP located exclusively in the cytoplasm) into the “negative” bin. See the bottom-right panel of Fig. 7 for examples of negative cells.</li>
<li>Once you have at least 5 cells in the positive bin and 5 cells in the negative bin, change the classifier from ‘Random Forest’ to ‘Fast Gentle Boosting’ and click the “Train Classifier” button. If you did not receive 5 clearly positive &amp; 5 clearly negative cells, in the first batch of 20 randomly selected cells you received, then hit the “Fetch!” button again, until you receive enough cells to be able to put 5 in each bin.
<ul>
<li>Note that in this portion of the exercise, the cell images that are provided to you are a random sampling of the data. Thus, depending on which cell images are allocated to you, your sorting into these two bins will take varying amounts of time. Subsequently, the results of this portion of the exercise will not look the same from user to user.</li>
<li>We refer to this set of positive and negative cells you have assembled as the “training set.”</li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>Reviewing the rules that CPA established (based on your training set) to classify positive and negative cells</strong></li>
</ol>
<p>The classification rules you will examine below are CPA’s way of defining the measurements (and the cutoff values the measurements need to have) in order to distinguish the positive from the negative phenotypes.</p>
<ul>
<li>Read the text that is now located in the text box in the upper half of the Classifier window. This text contains the rules CPA found based on the training set you provided to it.
<ul>
<li>Each rule is in the form an “IF” statement evaluating whether a measurement is greater than some value.</li>
<li>The closer to the top of the list a measurement appears, the more significant it is in distinguishing the phenotypes.</li>
</ul></li>
<li>Questions to consider: (1) What is the top-most measurement that shows up in your classification rules? (2) Is the top-most measurement one that you would expect to be the most significant one to use, in distinguishing the phenotypes?</li>
</ul>
<ol start="4" type="1">
<li><strong>Reviewing the accuracy of the classification with the confusion matrix</strong></li>
</ol>
<p>Once you have trained a classifier, you can test the ability of the of the classification rules to predict which class each cell in your training set belongs to. CPA does this by taking each cell in the training set, using its measurements and the rules generated in training to ‘guess’ whether it should be positive or negative, then comparing that answer with the bin you actually placed it in. The accuracy of these predictions can be graphed in a matrix with the ‘True label’ (the bin you assigned) on the Y axis and the ‘Predicted label’ (CPA’s guess) on the X axis.</p>
<ul>
<li>Press the ‘Evaluate’ button to generate a confusion matrix for the cells you’ve classified so far. How accurate is your classification after adding only a few cells to your training set?</li>
</ul>
<p>Note that the confusion matrix is NOT a measure of how accurate the classifier will be on your whole data set, simply a measure of <em>how well the classifier performs on your hand-picked examples</em>. As your data is likely more complicated than just the few cells you’ve chosen to train on, you shouldn’t stop at this point even if you have a perfect correlation matrix- you need to see how your classifier will perform on more data before you can decide whether it’s accurate enough to score the whole experiment.</p>
<table style="width:28%;">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
</colgroup>
<tbody>
<tr class="odd">
<td><img src="./TutorialImages/Fig8A.png" width="300" alt="Fig8A" /></td>
<td><img src="./TutorialImages/Fig8B.png" width="300" alt="Fig8B" /></td>
</tr>
</tbody>
</table>
<p><em>Figure 8: Examples of confusion matrices from a poorly-trained (left) and well-trained (right) classifier. The cells in the classifier on the left were assigned to bins of the training set at random, making it very difficult to come up with good rules to separate the classes; nearly 50% of each class is predicted incorrectly. The cells in the classifier on the right have been assigned to the correct bins, allowing the classifier to find rules that accurately predict which class the cells belong to. While the cells in this simple example were able to be predicted perfectly, that is rare in real data.</em></p>
<ol start="5" type="1">
<li><strong>Refining the training set by sorting more “unclassified” cells into the “positive” and “negative” bins</strong></li>
</ol>
<p>At this point, it is important to keep in mind that the CPA Classifier tool will pick whichever measurement is most significant in making its determination of positive versus negative (whether or not that measurement happens to be a physiologically relevant characteristic in the mind of the user).</p>
<p>For example, at this point (after only sorting 5 positive &amp; 5 negative cells), you may notice measurements called <em>“Object_Number”</em> (the object number of each cell) or <em>“Nuclei_Location_Center”</em> (the cell position in the image) included in the classification rules. This indicates that the classifier is not well-trained, since these measurements are not correlated with the phenotype we want to find. Whenever you find that the classifier is not well-trained, you need to either add more cells to the training set, or obtain more measurements from the cells.</p>
<p><strong>Refining the training set by obtaining samples from positive and negative control wells:</strong> Sometimes the phenotype of interest is uncommon enough, that fetching 20 random images will not result in the retrieval of many clear examples of the phenotype you are looking for. However, if you know which images contain examples of the phenotype, you can open the image - either by double-clicking a cell thumbnail, or from the <em>Plate Viewer</em> (if you know the location of the well). You can then drag-and-drop the cells of interest directly from the image.</p>
<ul>
<li>Open the <em>Plate Viewer</em> and double-click on well A01, in order to open an image from the negative controls.</li>
<li>Click on a cell in the image that is negative for the phenotype and drag-and-drop it into the negative bin. Repeat this for 5 negative cells.</li>
<li>Repeat the above two steps for A12 (a well containing a positive control sample), dropping the cells into the positive bin. Do this for 5 positive cells.</li>
<li>Click the “Train classifier” button.</li>
</ul>
<p><strong>Refining the training set by correcting misclassified cells in an image:</strong> You may also apply the rules to all the identified cells in an image, and use it to correct misclassifications.</p>
<ul>
<li>Double-click any of cell thumbnails in the positive or negative bins.</li>
<li>From the image that opens, click “Classify” from the menu, then “Classify Image”.</li>
<li>The cells will be color-coded according to their classification based on the current rules.
<ul>
<li>On Windows computers, to see each color means, click the “Show controls &gt;&gt;” button at the bottom to reveal the colored class list.</li>
<li>On Macs, select “View” from the image menu, and then select “View cell classes as numbers.” Then, to see what each number means, click the “Show controls &gt;&gt;” button at the bottom to reveal the numbered class list.</li>
</ul></li>
<li>Look for up to 5 cells that are clearly misclassified. For each of these cells that you find, click on it and drag-and-drop it into the appropriate bin.</li>
<li>Click the “Train classifier” button.</li>
</ul>
<p><strong>Refining the training set by fetching positive and negative cells:</strong> You now have your initial training set, and the rules that define the computer’s first attempt at distinguishing the phenotype. Therefore you can now request that the computer fetch more examples of positive and negative cells. These new sample cells can be added to the corresponding bins, in order to improve the classifier’s performance, with respect to distinguishing the FOXO1A-GFP subcellular localization phenotypes.</p>
<ul>
<li>Change the number next to the word “Fetch” from “20” to “5”. Click on the drop-down box labeled “random” in the fetch controls. Select “positive” from the drop-down list.</li>
<li>Click the “Fetch!” button to retrieve samples of what the computer thinks are positive cells based on the current set of rules. Refine your training set by doing the following:
<ul>
<li>If positive cells are correctly fetched (true positives), drag and drop them into the positive bin.</li>
<li>If negative cells are incorrectly fetched (false positives), drag and drop them into the negative bin.</li>
</ul></li>
</ul>
<p>As with previous steps, if you are not sure about which bin a cell belongs to, do not add it to the training set. Instead, click to select these ambiguous cells, and then press the “Delete” key to remove them from the analysis.</p>
<p>Repeat this step until you have at least 20 cells in each bin.</p>
<ul>
<li>Click the “Train classifier” button.</li>
<li>Questions to consider: (1) What is the top-most rule that shows up in your classification rules? (2) Is the top-most rule a measurement that you would expect to be the most significant one to use, in distinguishing the phenotypes?</li>
</ul>
<p>Whatever approach you choose to obtain more positive and negative cells, the procedure is the same: (i) Find rules; (ii) Obtain more cell samples of the desired phenotype; (iii) Correct misclassifications, or sort into appropriate bins; (iv) Go back to the first step and repeat, until the classifier displays the desired level of accuracy.</p>
<ol start="6" type="1">
<li><strong>Classifying all cells in the experiment</strong></li>
</ol>
<p>Once the classifier is of the desired accuracy, it is ready to be applied to the complete image data set.</p>
<ul>
<li>Press the “Score all” button. A dialog box will appear with scoring options; click “OK” to accept the default settings and begin scoring. Every cell in every image will now be scored as positive or negative by the classifier you built.</li>
</ul>
<p>A “Hit table” window will appear containing the summarized scores for every image (Fig. 9). The total cell count is reported, as well as the number of positive and negative cells classified. The last column is the enrichment score.</p>
<ul>
<li>Click on the column header labeled “Enriched Score positive.” (You can resize the hit table window, if this column is not visible). Clicking this header will sort the rows in ascending or descending order, according to the enrichment scores. Sort the column values so the order is descending, with the highest score at top.</li>
<li>Double-click on the asterisk in the first row to the left of the first column (“ImageNumber”) to display the corresponding image for the top-scoring well.</li>
</ul>
<figure>
<img src="./TutorialImages/Fig9.png" class="align-center" width="600" alt="Figure 9: Hit table showing the cell counts and enrichment scores." /><figcaption aria-hidden="true"><em>Figure 9: Hit table showing the cell counts and enrichment scores.</em></figcaption>
</figure>
<p>You can also save your training set and/or classifer model for future reference or to make changes later; do so by going to <em>File &gt; Save Training Set</em> or <em>File &gt; Save Classifier Model</em></p>
<ol start="7" type="1">
<li><strong>Saving the scores to the measurement database for visualization</strong></li>
</ol>
<p>Now that we have successfully scored our experiment, we will save the scores back to the measurement database, so that they can be visualized using CPA’s tools.</p>
<ul>
<li>Select the “Hit table” window and click “File” from the menu, then “Save table to database.” When prompted for a name, enter “HitTable”. Select “save permanently” when prompted.</li>
<li>Select Plate Viewer from the CPA interface, then choose “*OTHER TABLE*” from “Data source.”</li>
<li>When prompted to select a table, choose “HitTable.”</li>
<li>At the next prompt, select “per-well” as the table type. Then select the matching columns in order to link the table of hits to the table of image measurements, by doing the following:
<ul>
<li>On the first row, choose “<em>PlateID</em>” on the left to match “<em>Image_Metadata_Plate</em>” on the right.</li>
<li>On the second row, choose “<em>Image_Metadata_Well</em>” on the left to match “<em>Image_Metadata_Well</em>” on the right.</li>
</ul></li>
<li>Open a new Plate Viewer tool from the CPA menu. On the Plate Viewer, select “<em>pEnriched_positive”</em> from the <em>Measurement</em> drop-down list in order to view the enrichment scores in the plate layout.</li>
<li>Refer to the previous Plate Viewer display of <em>“Image_Metadata_Dose</em>” from section 2A. Consider the following questions: (1) How well does the layout of the “<em>pEnriched_positive</em>” values match the layout of the (i) positive and negative control wells and (ii) the 9-point dose wells of “<em>Image_Metadata_Dose</em>”? (2) What does this correspondence (or lack thereof) tell you about the classifier?</li>
</ul>
<ol start="8" type="1">
<li><strong>Plotting the scoring results, to estimate the lowest dose necessary to induce FOX1O-GFP translocation</strong></li>
</ol>
<p>You can use additional data tools in CPA to visualize your data in other ways. In this case, we will use a scatter plot to plot a dose-response curve. This will allow us to see how the ratio of positive cells (i.e. cells with GFP in the nucleus) increases with Wortmannin dose.</p>
<ul>
<li>Click the Scatter Plot icon in the CPA menu <img src="./TutorialImages/Inline11.png" alt="Inline11" />, 4th from left).</li>
<li>From the “x-axis” row, select “<em>Per_image</em>” and “<em>Image_Metadata_Dose</em>” from the drop-down lists. Choose “<em>log</em>” from the “Scale” drop-down.</li>
<li>From the “y-axis” row, select “<em>HitTable</em>” and “<em>pEnriched_positive</em>” from the drop-down-lists.</li>
<li>Click the “Update chart” button to see the scatter plot. NOTE: due to a bug in CPA, if you have plot the graph once in “<em>linear</em>” scale mode and then try to switch to “<em>log</em>” scale an error will be thrown. If you want to look at both, open two separate scatter plots.</li>
<li>In the space below, record your questions to the following questions:
(1) What is the enrichment score (<em>pEnriched_positive</em>) that corresponds to the highest dose (<em>Image_Metadata_Dose</em>) in the experiment? (There are several points corresponding to the highest dose, so estimate the average enrichment score) (2) What is the lowest dose that produces an enrichment score similar to that of the maximum dose?</li>
</ul>
<hr />
<p><strong>*To learn more about CellProfiler, please see our website:</strong>*</p>
<ul>
<li>Download CellProfiler and CellProfiler Analyst from the “Download” links on <a href="https://cellprofiler.org/">https://cellprofiler.org/</a> and <a href="https://cellprofileranalyst.org/">https://cellprofileranalyst.org/</a>, and install according to the instructions from the download page. This webpage also provides tutorials and example pipelines.</li>
<li>Visit the Scientific Community Image Forum at <a href="https://forum.image.sc/">https://forum.image.sc/</a> to find answers to common questions and ask for help if needed.</li>
<li>Video tutorials that may be helpful are available on the Center for Open Bioimage Analysis YouTube channel: <a href="https://www.youtube.com/channel/UC_id9sE-vu_i30Bd-skay7Q/">https://www.youtube.com/channel/UC_id9sE-vu_i30Bd-skay7Q/</a>.</li>
<li>Download sample images and the text file of experimental parameters used in this exercise from <a href="https://cellprofiler-examples.s3.amazonaws.com/TranslocationData.zip/">https://cellprofiler-examples.s3.amazonaws.com/TranslocationData.zip/</a>. (The images were kindly provided through the Broad Bioimage Benchmark Collection at <a href="http://www.broadinstitute.org/bbbc/BBBC013/">http://www.broadinstitute.org/bbbc/BBBC013/</a>)</li>
</ul>
