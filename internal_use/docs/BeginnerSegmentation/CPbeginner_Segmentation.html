<h1 id="segmentation-and-organelle-analysis">Segmentation and organelle
analysis:</h1>
<h1 id="a-computer-exercise-using-cellproï¬ler">A computer exercise using
CellProï¬ler</h1>
<h2 id="beth-cimini-barbara-diaz-rohrer-and-rebecca-senft">Beth Cimini,
Barbara Diaz-Rohrer and Rebecca Senft</h2>
<h2 id="broad-institute">Broad Institute</h2>
<p><strong>Background information:</strong></p>
<p>The images in this experiment come from the <a
href="https://data.broadinstitute.org/bbbc/BBBC022/">Broad Bioimage
Benchmark Collection</a>. They are ï¬elds of U2OS cells imaged in ï¬ve
channels (Cell Painting assay; see Gustafsdottir et al., 2013)</p>
<p><img src="./TutorialImages/Fig1.png" class="align-center" width="700"
alt="image1" /></p>
<p><em>Figure 1: Images and channels from a Cell Painting
assay.</em></p>
<p><strong>Goals of this exercise:</strong></p>
<p>This exercise will give you practice ï¬nding segmentation parameters
for larger â€œparentâ€ objects (nucleus, cell, and cytoplasm) and show you
ways to pull out smaller features in your image by segmenting organelles
within the cells and nuclei. You will also be shown how to use
RelateObjects so that you can relate the average counts, distances, and
measurements of the smaller â€œchildâ€ organelles to their larger â€œparentâ€
objects (i.e., cell and nucleus).</p>
<p><strong>Materials necessary for this exercise:</strong></p>
<p>The images are contained in the <strong>images</strong> folder; these
50 images (10 sites imaged in 5 channels) represent 5 mock treated wells
from a single 384 well plate experiment.</p>
<p><strong>Exercise instructions:</strong></p>
<p>Read through the steps below and follow instructions where stated.
Steps where you must figure out a solution are marked with ğŸ”´ <em>TO
DO.</em></p>
<p><strong>1. Load starting pipeline (2 min)</strong></p>
<ul>
<li>Start CellProï¬ler by double-clicking the desktop icon: <img
src="./TutorialImages/icon.png" style="width:0.26065in;height:0.26065in"
alt="image2" /></li>
<li>Drag and drop the â€˜segmentation_start.cppipeâ€™ ï¬le into the â€˜Analysis
modulesâ€™ pane on the left.</li>
<li>2 modules should pop up.</li>
</ul>
<p><strong>2. Set up the input modules (10min)</strong></p>
<p>The four input modules (Images, Metadata, NamesAndTypes, and Groups)
are crucial for any CellProfiler pipeline because they define how images
are loaded and organized in CellProfiler.</p>
<ul>
<li>Click on the â€˜Imagesâ€™ module in the top left corner of the
CellProfiler window.</li>
<li>Drag and drop the â€˜imagesâ€™ folder into the â€˜Drop files and folders
hereâ€™ pane. It should automatically populate. Notice that illumination
correction images (with a ï¬le extension of â€˜.npyâ€™) are included in this
data set.</li>
<li>Notice that if the â€˜Filter images?â€™ is set to â€˜Images onlyâ€™ the
â€˜.npyâ€™ files appeared grey out.</li>
</ul>
<p><img src="./TutorialImages/Fig2.png" class="align-center"
style="width:7in;height:2.74931in" alt="image3" /></p>
<p><em>Figure 2: The Images module, grey out files will not be available
for downstream modules</em></p>
<ul>
<li>** ğŸ”´ TO DO*<em>: Change the filter to a custom filter
toinclude</em>* the â€˜.npyâ€™ files.</li>
<li>In the â€˜Metadataâ€™ module three metadata extraction methods should
already be present and conï¬gured:
<ul>
<li>The ï¬rst pulls Well, Site, and Channel metadata from all the image
ï¬les except for the illumination correction functions.</li>
<li>The second pulls Plate metadata from the image folder.</li>
<li>The third pulls Plate metadata from the illumination correction
functions.</li>
</ul></li>
<li>Click on the magnifying glass at the end of the regular expression
box for each extraction method to see how it works.</li>
<li>Return to the â€˜Metadataâ€™ module and press â€˜Updateâ€™. You should now
see several columns, look through them you should have 5 different
channel numbers, 1 plate, 2 sites and 5 different wells.</li>
</ul>
<p><img src="./TutorialImages/Fig3.png" class="align-center" width="700"
alt="image4" /></p>
<p><em>Figure 3: The Metadata module, columns in table correspond to
metadata categories</em></p>
<ul>
<li>In the â€˜NamesAndTypesâ€™ module, we assign names to the images and
configure image sets (i.e., all the different channels for a field of
view). The channel mapping here is a bit complicated â€“ we have a single
set of illumination correction images (one â€˜.npyâ€™ file per channel) that
map to each and every well and site. We will use the metadata we
extracted in the previous module to make that association possible.</li>
<li>The â€˜NamesAndTypesâ€™ module is fully configured already but scroll
and look through the configuration to see the two different ways of
mapping images to channel names that are demonstrated here. (There are
several other ways to create correct mappings, but these may serve as a
helpful example to refer to in your own work).
<ul>
<li>The â€˜.tifâ€™ image ï¬les are assigned a name by the Metadata extracted
in the previous module (speciï¬cally ChannelNumber)</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig4.png" class="align-center" width="700"
alt="image5" /></p>
<p><em>Figure 4: Image mapping using extracted metadata</em></p>
<ul>
<li>The â€˜.npyâ€™ illumination correction functions are assigned a name
based on a unique string in the filename (such as â€˜IllumERâ€™)</li>
</ul>
<p><img src="./TutorialImages/Fig5.png" class="align-center" width="700"
alt="image6" /></p>
<p><em>Figure 5: Image mapping using filename</em></p>
<ul>
<li>As there is only one set of illumination correction functions for
each entire plate, the image sets cannot simply be constructed by using
â€˜Image set matchingâ€™ as â€˜Orderâ€™.</li>
<li>Scroll to the bottom of the â€˜NamesAndTypesâ€™ to see how the image
sets are constructed â€˜Image set matchingâ€™ is set to â€˜Metadataâ€™
<ul>
<li>Each image channel is set to â€˜Plate â†’ Well â†’ Siteâ€™.</li>
<li>Each illumination correction function is set to â€˜Plate â†’ (None) â†’
(None)â€™</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig6.png"
style="width:7.5in;height:0.60764in" alt="image7" /></p>
<p><em>Figure 6: Image set matching using extracted metadata</em></p>
<ul>
<li>For this exercise the â€˜Groupsâ€™ module is not needed so it is set to
â€˜Noâ€™, this module can be useful when you have more than one plate, or
different movies.</li>
<li>For more information and examples on how to configure the Input
modules we have created a blog and video tutorial that can be accessed
here: <a
href="https://carpenter-singh-lab.broadinstitute.org/blog/input-modules-tutorial">https://carpenter-singh-lab.broadinstitute.org/blog/input-modules-tutorial</a>.</li>
</ul>
<p><strong>3. Examine the output of the CorrectIlluminationApply module.
(2min)</strong></p>
<p>Since microscope objectives donâ€™t typically have a completely uniform
illumination pattern, applying an illumination correction function can
help improve our segmentation and measurements by compensating for this.
Pay close attention to the top of the ï¬eld of view to see the greatest
effect of correction.</p>
<ul>
<li>Enter test mode by clicking on the â€˜Start Test Modeâ€™ button at the
bottom left corner of the window and hit â€˜Stepâ€™ to run the
CorrectIlluminationApply module.</li>
<li>Brieï¬‚y examine the output of the CorrectIlluminationApply moduleâ€”you
can see that the illumination correction functions show uneven
illumination across the ï¬eld of view.</li>
<li>These functions were created by averaging and smoothing all 3456
images from this plate, so dim areas in the illumination correction
function are areas of the field of view that are consistently dimmer
across many images.</li>
<li>Also note that while the illumination correction functions for each
channel are similar, they arenâ€™t identical; each channel in your own
experiments should therefore be illumination corrected
independently.</li>
</ul>
<p><img src="./TutorialImages/Fig7.png" class="align-center" width="700"
alt="image8" /></p>
<p><em>Figure 7: Application of the illumination correction
function</em></p>
<p><strong>4. IdentifyPrimaryObjects â€“ Nuclei (10min)</strong></p>
<p>Next, weâ€™ll take a ï¬rst pass at identifying nuclei and cells in our
initial image.</p>
<ul>
<li>After the CorrectIlluminationApply module, add an
IdentifyPrimaryObjects module (from the â€˜Object Processingâ€™ module
category). Do this by clicking on the â€˜+â€™ sign in the bottom left corner
of the CellProfiler window, which will pop up a small window called â€˜Add
modules.â€™.
<ul>
<li>Tip: You can also use the search bar at the top of the â€˜Add modulesâ€™
window to search all modules by name.</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig8.png" class="align-middle" width="400"
alt="image9" /></p>
<p><em>Figure 8: The Add modules window, modules are divided in
categories based on their function</em></p>
<ul>
<li>Create objects called Nuclei by segmenting on the Hoechst channel.
<ul>
<li>Select â€˜Hoechstâ€™ image as your input image from the drop-down
menu.</li>
<li>Change the name of the output objects to â€˜Nucleiâ€™.</li>
</ul></li>
<li>Hitâ€™ Stepâ€™ to run the module. How does your segmentation look?</li>
<li>On the outlines display pane (bottom left) you can see three
different colors; green is for accepted objects, orange for objects
touching the border, and pink for objects outside the diameter
range.</li>
<li>On the table pane (bottom right) there is useful information that
you can use to adjust your segmentation settings, like the median
diameter, and the threshold.</li>
</ul>
<p><img src="./TutorialImages/Fig9.png" class="align-center" width="700"
alt="image10" /></p>
<p><em>Figure 9: The IdentifyPrimaryObjects module output, you can use
the information in this window to modify your segmentation
parameters</em></p>
<ul>
<li>Use the magnifying glass at the top of the window to zoom in on an
area that was segmented poorly.</li>
<li><strong>ğŸ”´ TO DO</strong>: Improve your segmentation of nuclei:
<ul>
<li>Select â€˜Yesâ€™ for the â€˜Use advanced settings?â€™ option, then change
some of the parameters:
<ul>
<li>Adjust the threshold method, may lead to better (or worse!)
results.</li>
<li>Adjust the declumping settings.</li>
</ul></li>
<li>Hit â€˜Stepâ€™ to rerun and see how the changes affect the
segmentation.</li>
<li>Adjust the segmentation parameters until you feel youâ€™re ready to
move on to identifying the cells around the nuclei; the identiï¬cation
should be good but doesnâ€™t need to be perfect before you move on.</li>
</ul></li>
</ul>
<ol type="1">
<li><strong>IdentifySecondaryObjects â€“ Cells (5min)</strong></li>
</ol>
<ul>
<li>After the IdentifyPrimaryObjects, add an IdentifySecondaryObjects
module.</li>
<li>Create an object called Cells that is seeded on the Nuclei primary
objects that you just created; select the Ph_golgi image for your input
image, nuclei for input objects and change the name to â€˜Cellsâ€™.</li>
<li>Hitâ€™ Stepâ€™ to run the module. How does your segmentation look?</li>
<li>For this module the outline colors correspond to the object seed
(green-nuclei) and the segmented objects (pink-cell)</li>
</ul>
<p><img src="./TutorialImages/Fig10.png" class="align-center"
width="700" alt="image11" /></p>
<p><em>Figure 10: The IdentifySecondaryObjects module output</em></p>
<ul>
<li><strong>ğŸ”´ TO DO</strong>: Improve cell segmentation
<ul>
<li>Examine the segmentation and adjust the segmentation parameters
until you feel youâ€™re ready to test them on another image; they donâ€™t
need to be perfect.</li>
<li>Adjust the threshold method.</li>
<li>Test the effects of using the various methods for identifying
secondary objects (Propagation, Watershed-Image, Distance-N, etc) and,
if using Propagation, the regularization factor.</li>
</ul></li>
</ul>
<p><strong>6. Test the robustness of your segmentation parameters across
images (5min)</strong></p>
<p>Itâ€™s (relatively!) easy to come up with a good set of segmentation
parameters for a single image however we aim to create a set of
parameters that can segment cells on all the images on an
experiment.</p>
<ul>
<li>To test the parameters, there are two options to change the image
you are working on in Test Mode
<ul>
<li>Click on the â€˜Next Image Setâ€™ at the bottom left corner, or</li>
<li>Go to â€˜Testâ€™ on the top menu bar â†’ Choose Image Set to bring up a
list of the images in your experiment, select the image you want to
test, and press the â€˜OKâ€™ button.
<ul>
<li>Tip: you can also use the Test menu to choose a random image
set</li>
</ul></li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig11.png" class="align-center"
width="700" alt="image12" /></p>
<p><em>Figure 11: A section of the â€˜Choose Image Setâ€™ menu.</em></p>
<ul>
<li>Then run that image in test mode for your ï¬rst 3 modules (through
your IdentifySecondaryObjects step).
<ul>
<li>You can do it by clicking the step button, or</li>
<li>You can add a pause button on the module after
IdentifySecondaryObjects and hit â€˜Runâ€™, this will run all modules before
the pause.</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig12.png" class="align-center"
width="400" alt="image13" /></p>
<p><em>Figure 12: A section of the â€˜Analysis modulesâ€™ pane.</em></p>
<ul>
<li>Examine the output â€“ did your nuclear and cellular segmentation hold
up compared to the ï¬rst images you looked at?</li>
<li><strong>ğŸ”´ TO DO</strong>: Adjust the parameters to get comparable
results to the first image. Once your segmentation is good, try it on
another image.</li>
</ul>
<p><strong>7. IdentifyTertiaryObjects- Cytoplasm (2min)</strong></p>
<ul>
<li>After the IdentifySecondaryObjects module, add an
IdentifyTertiaryObjects module.</li>
<li>Create an object called Cytoplasm using the Cell and Nuclei objects
youâ€™ve created.
<ul>
<li>Select the larger and smaller identified objects from the drop-down
menu.</li>
<li>Change the name of the objects to be identified.</li>
<li>â€˜Shrink smaller object prior to subtraction?â€™ should both set to
â€˜Noâ€™.</li>
</ul></li>
</ul>
<p><strong>8. Examine the steps used to segment the Nucleoli
(15min)</strong></p>
<p>So far, we have used untransformed images for object detection, but
not all objects can be segmented from raw images. CellProfiler contains
a variety of image processing modules that can aid segmentation. For
this exercise, we will use two such modules, but there are other ones
you can explore.</p>
<p>The next 3 modules have to do with the creation of the Nucleoli
objects. Look at the output from each to see how the image is
transformed to aid in segmentation.</p>
<ul>
<li><p>After the IdentifyTertiaryObjects module, add an
EnhanceOrSuppressFeatures module.</p></li>
<li><p>EnhanceOrSuppressFeatures is a module that helps enhance parts of
an image- in this case, punctate objects or â€˜Specklesâ€™. As we are
looking for nucleoli, we apply this to the RNA channel (Syto) image and
call the output â€˜FilteredRNAâ€™.</p>
<p><strong>ğŸ”´ TO DO: Enhance nucleoli spots</strong></p>
<ul>
<li>Change the input image from the drop-down menu to â€˜Sytoâ€™</li>
<li>Change the name of the output image to â€˜FilteredRNAâ€™</li>
<li>Change the feature size to see how this affects the output and find
a value that works well.</li>
<li>See below for an example of results to aim for:</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig13.png" class="align-center"
width="700" alt="image14" /></p>
<p><em>Figure 13. The EnhanceOrSuppress module output, enhancing the
Syto image allows you to isolate nucleoli against the nucleoplasmic
background signal.</em></p>
<ul>
<li><p>After the EnhanceOrSuppressFeatures module, add an MaskImage
module.</p></li>
<li><p>MaskImage allows you to create a version of the â€˜FilteredRNAâ€™
image called â€˜SytoNucleiâ€™ where all the pixels except the ones you
specify are set to an intensity of 0. In this case, we set to 0 any
pixel not inside a nucleus. By doing this, we can decrease the
likelihood of detecting cytoplasmic RNA dots.</p>
<p><strong>ğŸ”´ TO DO: Mask the RNA image to show only the
â€˜Nucleiâ€™</strong></p>
<ul>
<li>Change the input image from the drop-down menu to â€˜FilteredRNAâ€™</li>
<li>Change the name of the output image to â€˜SytoNucleiâ€™</li>
<li>Use the objects â€˜Nucleiâ€™ as the mask.</li>
<li>See below for an example of results to aim for:</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig14.png" class="align-center"
width="700" alt="image15" /></p>
<p><em>Figure 14. The MaskImage module output, the contrast was adjusted
to show that the intensity of the pixels outside the nuclei are now set
to 0.</em></p>
<ul>
<li><p>IdentifyPrimaryObjects is used to ï¬nd the Nucleoli. This is a
Primary object segmentation because we are not using another object as a
seed (i.e., starting point), and are only segmenting based off the
intensity in our â€˜SytoNucleiâ€™ image.</p>
<p><strong>ğŸ”´ TO DO: Segment nucleoli</strong></p>
<ul>
<li>Change the input image from the drop-down menu to â€˜SytoNucleiâ€™</li>
<li>Change the name of the objects to â€˜Nucleoliâ€™</li>
<li>Adjust the segmentation parameters until you are satisfied with the
segmentation results.</li>
</ul>
<p><strong>ğŸ”´ TO DO</strong>: Add an â€˜OverlayOutlinesâ€™ module at this
point to overlay the identiï¬ed nucleoli on the original Syto image to
assure yourself that the segmentation not only matches the speckle
enhanced â€˜SytoNucleiâ€™ image, but also looks accurate on the unprocessed
image as well. This is not strictly necessary but can be a nice â€œsanity
checkâ€.</p>
<ul>
<li>Goal: display outlines of your nucleoli and your nuclei on the
unprocessed â€˜Sytoâ€™ image.</li>
<li>Hereâ€™s an example of what that could look like (red=nuclei,
green=nucleoli):</li>
<li>Tip: you can use a similar strategy to segment mitochondria using
the â€˜Mitoâ€™ channel</li>
</ul></li>
</ul>
<p><img src="./TutorialImages/Fig15.png" class="align-center"
width="700" alt="image16" /></p>
<p><em>Figure 15. The OverlayOutlines module output, all detected
nucleoli are within the nuclei.</em></p>
<p><strong>9. ğŸ”´ TO DO: Add measurement modules to your pipeline
(10min)</strong></p>
<ul>
<li>After your segmentation of the nucleoli, add as many object
measurement modules as you would like, we have added a
MeasureObjectIntensity.</li>
<li>Some suggested modules to add: MeasureObjectSizeShape,
MeasureObjectIntensity, MeasureGranularity, MeasureObjectNeighbors.</li>
<li>Which objects do you think would be valuable to measure with each of
these modules? Which channels would you measure your objects in? For a
typical Cell Painting experiment you would add as many measurements as
possible, but that isnâ€™t necessary here; however, do make sure every
object gets at least some measurements.Note: While MeasureCorrelation,
MeasureTexture, and MeasureObjectIntensityDistribution can produce
valuable data for downstream proï¬ling, they can be memory-intensive
and/or slow so should not be added for this example pipeline in the
interest of pipeline runtime.</li>
</ul>
<p><strong>10. RelateObjects (5min)</strong></p>
<ul>
<li><strong>ğŸ”´ TO DO:</strong> Add a RelateObjects module and configure
it to relate â€˜Nucleoliâ€™ to â€˜Nucleiâ€™.</li>
</ul>
<p><img src="./TutorialImages/Fig16.png" class="align-center"
width="700" alt="image17" /></p>
<p><em>Figure 16: The RelateObject module output.</em></p>
<p>Relating the objects allows you to create per-parent means (e.g., for
this cell, what is the average size of an individual mitochondrion) and
calculate distances from the child objects to the edge and/or the center
of the parent (e.g., how far is each nucleolus from the center of the
nucleus).</p>
<p><strong>11. Run the pipeline (optional)</strong></p>
<ul>
<li>If you have time, add a ExportToSpreadsheet module at the end.</li>
<li>Exit test mode.</li>
<li>Click on â€˜Output Settingsâ€™ button at the bottom left corner.</li>
<li>Change the default output folder.</li>
<li>Click on â€˜Analyze Imagesâ€™ button at the bottom left corner.</li>
<li>Explore the spreadsheets created for each object.</li>
</ul>
